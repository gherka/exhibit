#---------------------------------------------------------
#This specification describes the dataset in great detail.
#In order to vary the degree to which it is anonymised,
#please review each section and make necessary adjustments
#---------------------------------------------------------
metadata:
  number_of_rows: 2000
  categorical_columns:
  - age
  - hb_code
  - hb_name
  - measure
  - sex
  numerical_columns:
  - avlos
  - los
  - stays
  time_columns:
  - quarter_date
  category_threshold: 150
  random_seed: 0
  id: 3666f
#---------------------------------------------------------
#Dataset columns can be one of the three types: 
#Categorical | Continuous | Timeseries
#
#Column type determines the parameters in the specification.
#When making changes to the values, please note their format.
#
#The default anonymising method is "random", but you can add your
#own custom sets, including linked, by creating a suitable
#table in the anon.db SQLite3 database (using db_util.py script)
#
#The tool comes with a linked set of mountain ranges (15) and
#their top 10 peaks. Only linked sets can be used for linked columns
#and the number of columns in the linked table must match the number
#of linked columns in your data. For 1:1 mapping, there is a birds
#dataset with 150 values
#
#To use just one column from a table, add a dot separator like so:
#mountains.ranges
#---------------------------------------------------------
columns:
  age:
    type: categorical
    paired_columns: []
    uniques: 10
    original_values:
    - age          | probability_vector | avlos | los   | stays
    - 0-9          | 0.061              | 0.016 | 0.005 | 0.017
    - 10-19        | 0.098              | 0.037 | 0.009 | 0.027
    - 20-29        | 0.103              | 0.049 | 0.024 | 0.058
    - 30-39        | 0.105              | 0.055 | 0.034 | 0.074
    - 40-49        | 0.105              | 0.076 | 0.056 | 0.097
    - 50-59        | 0.108              | 0.094 | 0.105 | 0.165
    - 60-69        | 0.108              | 0.118 | 0.158 | 0.197
    - 70-79        | 0.109              | 0.151 | 0.244 | 0.209
    - 80-89        | 0.108              | 0.191 | 0.274 | 0.130
    - 90+          | 0.095              | 0.212 | 0.089 | 0.026
    - Missing data | 0.000              | 0.000 | 0.000 | 0.000
    allow_missing_values: true
    miss_probability: 0.0
    anonymising_set: random
  hb_code:
    type: categorical
    paired_columns:
    - hb_name
    uniques: 14
    original_values: See paired column
    allow_missing_values: true
    miss_probability: 0.0
    anonymising_set: random
  hb_name:
    type: categorical
    paired_columns:
    - hb_code
    uniques: 14
    original_values:
    - hb_name                     | paired_hb_code | probability_vector | avlos | los   | stays
    - NHS Ayrshire & Arran        | S08000015      | 0.071              | 0.069 | 0.053 | 0.051
    - NHS Borders                 | S08000016      | 0.045              | 0.041 | 0.013 | 0.012
    - NHS Dumfries & Galloway     | S08000017      | 0.060              | 0.049 | 0.020 | 0.018
    - NHS Fife                    | S08000029      | 0.064              | 0.054 | 0.035 | 0.036
    - NHS Forth Valley            | S08000019      | 0.047              | 0.051 | 0.034 | 0.022
    - NHS Grampian                | S08000020      | 0.066              | 0.081 | 0.057 | 0.054
    - NHS Greater Glasgow & Clyde | S08000021      | 0.176              | 0.180 | 0.190 | 0.210
    - NHS Highland                | S08000022      | 0.100              | 0.107 | 0.030 | 0.029
    - NHS Lanarkshire             | S08000023      | 0.092              | 0.082 | 0.065 | 0.080
    - NHS Lothian                 | S08000024      | 0.089              | 0.120 | 0.107 | 0.097
    - NHS Orkney                  | S08000025      | 0.041              | 0.033 | 0.002 | 0.003
    - NHS Shetland                | S08000026      | 0.042              | 0.031 | 0.002 | 0.003
    - NHS Tayside                 | S08000030      | 0.083              | 0.075 | 0.052 | 0.039
    - Missing data                | Missing data   | 0.000              | 0.000 | 0.000 | 0.000
    allow_missing_values: true
    miss_probability: 0.0
    anonymising_set: random
  measure:
    type: categorical
    paired_columns: []
    uniques: 3
    original_values:
    - measure              | probability_vector | avlos | los   | stays
    - All Daycases         | 0.349              | 0.001 | 0.001 | 0.396
    - Elective Inpatients  | 0.318              | 0.289 | 0.103 | 0.117
    - Emergency Inpatients | 0.333              | 0.711 | 0.897 | 0.487
    - Missing data         | 0.000              | 0.000 | 0.000 | 0.000
    allow_missing_values: true
    miss_probability: 0.0
    anonymising_set: random
  sex:
    type: categorical
    paired_columns: []
    uniques: 2
    original_values:
    - sex          | probability_vector | avlos | los   | stays
    - A            | 0.500              | 0.514 | 0.533 | 0.514
    - B            | 0.500              | 0.486 | 0.467 | 0.486
    - Missing data | 0.000              | 0.000 | 0.000 | 0.000
    allow_missing_values: true
    miss_probability: 0.0
    anonymising_set: random
  los:
    type: continuous
    miss_probability: 0.0
    sum: 100000
    dispersion: 0.1
  stays:
    type: continuous
    miss_probability: 0.0
    sum: 50000
    dispersion: 0.1
  quarter_date:
    type: date
    allow_missing_values: false
    miss_probability: 0.0
    from: '2018-03-31'
    uniques: 4
    frequency: QS
#---------------------------------------------------------
#The tool will try to guess which columns are "linked",
#meaning that values cascade from one column to another.
#If any grouping is missed, please add it manually.
#---------------------------------------------------------
constraints:
  linked_columns: []
#---------------------------------------------------------
#Please add any derived columns to be calculated from anonymised
#continuous variable in this section, alongside with
#the calculation used. The calculation should follow the format
#of the evaluate method from Pandas framework: 
#
#Assuming you have Numerator column A and Denomininator column B,
#you would write Rate: (A / B)
#---------------------------------------------------------
derived_columns:
  Example_Column: Example_Calculation
  avlos: (los / stays)
